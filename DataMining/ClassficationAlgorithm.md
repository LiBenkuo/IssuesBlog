# 分类算法

- 决策树分类
- 贝叶斯分类
- 神经网络分类
- 支持向量机分类

分类：找出描述或识别数据类或概念的模型或函数以便能够使用模型预测类标记未知的对象类。

## 分类 vs. 聚类

- 分类 有监督学习
> - 模型的学习在被告知每个训练样本属于哪个类的指导下进行
> - 新数据使用训练数据集中得到的规则进行分类

- 聚类 无监督学习
> - 每个训练样本的类编号是未知的，要学习的类集合或数量也可能是事先未知的
> - 通过一系列的度量、观察来建立数据中的类编号或进行聚类

## 分类 vs. 预测

两种数据分析形式,都是用于提取描述重要数据类别或者是预测未来趋势的一种数据分析方式

### 相同点

- 两者都需要构建模型
- 都用模型来估计未知的值

### 不同点

- 分类法主要用来预测类别编号
- 预测法主要是用来估计连续值

## 分类的步骤

- 模型的创建
- 模型的使用

## 数据预处理

数据预处理可提高分类预测过程的准确性、有效性和可伸缩性。

- 数据清理
- 相关性分析
- 数据的变换与归约

## 分类算法衡量指标

- 预测的准确性
> 直接地衡量了模型正确预测新数据的类编号的能力

- 算法的时间复杂度（速度）
> 衡量产生和使用计算的我花销

- 健壮性

- 可伸缩性

- 可解释性

## 决策树的算法和步骤

- 类似于流程图的树结构
- 内部的每一个节点都表示在一个属性上的测试
- 每一个分支代表一个测试输出
- 每一个树叶节点存放一个类编号

### 使用决策树分类

- 给定一个类别标号未知的对象x
- 在决策树上测试对象的属性值
- 跟踪一条由跟到叶节点的路径
- 叶节点存放该对象的类预测

决策树比较容易转换成一些分类的规则。

### 决策树生成阶段

- **构建决策树**
> 利用属性选择度量来选择最佳分裂属性，然后递归地通过属性的选择来划分样本

- **树剪枝**
> 剪去因噪声和离群点生成的分支，以提高对未知数据分类的准确性和可伸缩性

### 决策树的输入

- 训练对象和对应类标号的集合
- 候选属性的集合
- 指定选择属性的启发性过程

### 决策树的算法步骤

- 以代表所有训练样本的单个节点作为根节点
- 如果样本在同一个类中，则该节点直接标记为叶子节点，并用类来标记叶子节点
- 如果样本不在同一个类中，则需要调用属性选择方法来选择能够最好的将样本分类的属性，然后确定分裂准则并指出分裂点和分裂子集
- 对测试属性每个已知的值创建分支并以此划分对象
- 将前面步骤重复和递归以形成决策树

> **递归划分停止条件**

> - 划分D内的所有对象已经属于同一类
> - 没有剩余属性可以用来进一步划分对象

## 决策树的分裂准则

属性选择度量 = 分裂准则
将给定类编号的训练对象进行最好划分的一个方法。

理想状态：没个划分都是`纯`的。

### 常用属性选择度量

- 信息增益（ID3）
- 增益率（C4.5）
- Gini指标

### 信息增益法

- 期望信息熵

- 属性的熵

信息增益值越高，属性重要性越高

### 过拟合的问题

- 许多分支反映的是训练集中的异常数据
- 分支对新样本判定很不精确


#### 防止过拟合方法

- 先剪枝
